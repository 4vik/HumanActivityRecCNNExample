{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    column_names = ['user-id','activity','timestamp', 'x-axis', 'y-axis', 'z-axis']\n",
    "    data = pd.read_csv(file_path,header = None, lineterminator=\";\", names = column_names)\n",
    "    return data\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis = 0)\n",
    "    sigma = np.std(dataset,axis = 0)\n",
    "    return (dataset - mu)/sigma\n",
    "    \n",
    "def plot_axis(ax, x, y, title):\n",
    "    ax.plot(x, y)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.set_ylim([min(y) - np.std(y), max(y) + np.std(y)])\n",
    "    ax.set_xlim([min(x), max(x)])\n",
    "    ax.grid(True)\n",
    "    \n",
    "def plot_activity(activity,data):\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows = 3, figsize = (15, 10), sharex = True)\n",
    "    plot_axis(ax0, data['timestamp'], data['x-axis'], 'x-axis')\n",
    "    plot_axis(ax1, data['timestamp'], data['y-axis'], 'y-axis')\n",
    "    plot_axis(ax2, data['timestamp'], data['z-axis'], 'z-axis')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    fig.suptitle(activity)\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.show()\n",
    "    \n",
    "def windows(data, size):\n",
    "    start = 0\n",
    "    while start < data.count():\n",
    "        yield start, start + size\n",
    "        start += (size / 2)\n",
    "\n",
    "def segment_signal(data,window_size = 90):\n",
    "    segments = np.empty((0,window_size,3))\n",
    "    labels = np.empty((0))\n",
    "    for (start, end) in windows(data['timestamp'], window_size):\n",
    "        start=int(start)\n",
    "        end=int(end)\n",
    "        x = data[\"x-axis\"][start:end]\n",
    "        y = data[\"y-axis\"][start:end]\n",
    "        z = data[\"z-axis\"][start:end]\n",
    "        if(len(dataset['timestamp'][int(start):int(end)]) == window_size):\n",
    "            segments = np.vstack([segments,np.dstack([x,y,z])])\n",
    "            labels = np.append(labels,stats.mode(data[\"activity\"][start:end])[0][0])\n",
    "    return segments, labels\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def depthwise_conv2d(x, W):\n",
    "    return tf.nn.depthwise_conv2d(x,W, [1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "def apply_depthwise_conv(x,kernel_size,num_channels,depth):\n",
    "    weights = weight_variable([1, kernel_size, num_channels, depth])\n",
    "    biases = bias_variable([depth * num_channels])\n",
    "    return tf.nn.relu(tf.add(depthwise_conv2d(x, weights),biases))\n",
    "    \n",
    "def apply_max_pool(x,kernel_size,stride_size):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, kernel_size, 1], \n",
    "                          strides=[1, 1, stride_size, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user-id activity       timestamp    x-axis    y-axis    z-axis\n",
      "0         33  Jogging  49105962326000 -0.000014  0.574004 -0.258150\n",
      "1         33  Jogging  49106062271000  1.143432  0.400749 -0.173418\n",
      "2         33  Jogging  49106112167000  1.121600  0.354104 -0.368558\n",
      "3         33  Jogging  49106222305000  0.016360  1.285349  0.216862\n",
      "4         33  Jogging  49106332290000 -0.098257  0.504036  1.005125\n",
      "5         33  Jogging  49106442306000  0.414792 -1.281823 -1.580480\n",
      "6         33  Jogging  49106542312000  0.016360  0.315788  0.722686\n",
      "7         33  Jogging  49106652389000  0.038192  0.728934  0.976881\n",
      "8         33  Jogging  49106762313000 -1.550078  0.419074  0.614845\n",
      "9         33  Jogging  49106872299000  0.330194 -0.808703 -0.042469\n",
      "10        33  Jogging  49106982315000 -1.503686  1.416956  0.160374\n",
      "11        33  Jogging  49107092330000  0.422979 -0.268948  0.209159\n",
      "12        33  Jogging  49107202316000 -0.237436 -1.341795 -0.409640\n",
      "13        33  Jogging  49107312332000 -1.088879 -0.139007 -1.891163\n",
      "14        33  Jogging  49107422348000  1.307171  1.225376  1.256753\n",
      "15        33  Jogging  49107522293000  1.397228 -0.612126  0.196321\n",
      "16        33  Jogging  49107632339000 -0.174669  0.039246 -0.627889\n",
      "17        33  Jogging  49107742355000  0.845972  0.685620  1.423649\n",
      "18        33  Jogging  49107852340000 -0.267454 -1.674978 -2.273740\n",
      "19        33  Jogging  49107962326000  0.693149  0.287467 -2.186441\n",
      "20        33  Jogging  49108062271000  0.854159  0.695616 -0.063010\n",
      "21        33  Jogging  49108172348000  0.038192 -0.503841  0.347811\n",
      "22        33  Jogging  49108272262000 -0.322034 -0.770387 -0.337746\n",
      "23        33  Jogging  49108382370000 -0.575830  1.416956  0.874176\n",
      "24        33  Jogging  49108492294000 -0.021846 -1.380111 -1.226147\n",
      "25        33  Jogging  49108602371000  0.240137  0.349106  2.196506\n",
      "26        33  Jogging  49108702285000  1.282610  0.930509  0.809985\n",
      "27        33  Jogging  49108812332000 -1.596471 -0.087363  0.404299\n",
      "28        33  Jogging  49108922378000 -0.128276 -0.827028  0.093616\n",
      "29        33  Jogging  49109022293000 -0.780504  1.416956  0.535248\n",
      "..       ...      ...             ...       ...       ...       ...\n",
      "570       33  Jogging  49166442306000  0.368400 -1.370116 -0.027063\n",
      "571       33  Jogging  49166552291000 -1.189852  0.390754  2.478945\n",
      "572       33  Jogging  49166662307000  0.652214  0.015923 -0.337746\n",
      "573       33  Jogging  49166772323000 -1.809332  0.100885  0.542951\n",
      "574       33  Jogging  49166882308000  0.414792 -0.667101  0.311865\n",
      "575       33  Jogging  49166982315000 -2.477934  1.411958  0.794579\n",
      "576       33  Jogging  49167092330000  0.698607 -1.093574  0.311865\n",
      "577       33  Jogging  49167462478000  0.693149 -0.563814  0.116725\n",
      "578       33  Jogging  49167562454000 -0.212875 -0.700419 -0.432749\n",
      "579       33  Jogging  49167662216000 -1.809332  1.393633  1.372296\n",
      "580       33  Jogging  49167762283000  0.139165 -1.370116 -0.101524\n",
      "581       33  Jogging  49167862228000 -0.412091  0.199174  1.993663\n",
      "582       33  Jogging  49167912246000 -2.224138  0.579002 -1.565074\n",
      "583       33  Jogging  49168012252000  0.545784  1.160405 -0.173418\n",
      "584       33  Jogging  49168122299000 -1.956697 -0.338916  0.252809\n",
      "585       33  Jogging  49168222274000  0.185557 -0.817033 -0.078415\n",
      "586       33  Jogging  49168322250000 -1.588284  1.416956  1.826767\n",
      "587       33  Jogging  49168432296000  0.032734 -0.920319 -0.063010\n",
      "588       33  Jogging  49168542343000 -0.674073  0.527358  2.586786\n",
      "589       33  Jogging  49168652297000  0.032734 -0.583805 -0.951410\n",
      "590       33  Jogging  49168752243000 -1.686528  0.067567  0.355514\n",
      "591       33  Jogging  49168852279000  1.536406 -0.723742 -0.301799\n",
      "592       33  Jogging  49168912429000  0.401147 -0.588803 -0.468695\n",
      "593       33  Jogging  49183789535000 -0.084612 -0.653773  1.169453\n",
      "594       33  Jogging  49183874710000 -0.060051 -0.607128  1.213103\n",
      "595       33  Jogging  49183932357000 -0.076425 -0.555485  1.164318\n",
      "596       33  Jogging  49184042312000 -0.076425 -0.338916  0.946069\n",
      "597       33  Walking  49394992294000  0.308362  0.002596  0.173212\n",
      "598       33  Walking  49395102310000  0.362942  0.077562  0.360649\n",
      "599       33  Walking  49395202316000  0.038192  1.060450 -0.106659\n",
      "\n",
      "[600 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = read_data('actitracker_raw_short.txt')\n",
    "dataset['x-axis'] = feature_normalize(dataset['x-axis'])\n",
    "dataset['y-axis'] = feature_normalize(dataset['y-axis'])\n",
    "dataset['z-axis'] = feature_normalize(dataset['z-axis'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for activity in np.unique(dataset[\"activity\"]):\n",
    "#    subset = dataset[dataset[\"activity\"] == activity][:180]\n",
    "#    plot_activity(activity,subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avik\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\stats\\stats.py:253: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "segments, labels = segment_signal(dataset)\n",
    "labels = np.asarray(pd.get_dummies(labels), dtype = np.float64)\n",
    "reshaped_segments = segments.reshape(len(segments), 1,90, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_split = np.random.rand(len(reshaped_segments)) < 0.70\n",
    "train_x = reshaped_segments[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "test_x = reshaped_segments[~train_test_split]\n",
    "test_y = labels[~train_test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_height = 1\n",
    "input_width = 90\n",
    "num_labels = 6\n",
    "num_channels = 3\n",
    "\n",
    "batch_size = 10\n",
    "kernel_size = 60\n",
    "depth = 60\n",
    "num_hidden = 1000\n",
    "\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 8\n",
    "\n",
    "total_batches = train_x.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,input_height,input_width,num_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,num_labels])\n",
    "\n",
    "c = apply_depthwise_conv(X,kernel_size,num_channels,depth)\n",
    "p = apply_max_pool(c,20,2)\n",
    "c = apply_depthwise_conv(p,6,depth*num_channels,depth//10)\n",
    "\n",
    "shape = c.get_shape().as_list()\n",
    "c_flat = tf.reshape(c, [-1, shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "f_weights_l1 = weight_variable([shape[1] * shape[2] * depth * num_channels * (depth//10), num_hidden])\n",
    "f_biases_l1 = bias_variable([num_hidden])\n",
    "f = tf.nn.tanh(tf.add(tf.matmul(c_flat, f_weights_l1),f_biases_l1))\n",
    "\n",
    "out_weights = weight_variable([num_hidden, num_labels])\n",
    "out_biases = bias_variable([num_labels])\n",
    "y_ = tf.nn.softmax(tf.matmul(f, out_weights) + out_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = -tf.reduce_sum(Y * tf.log(y_))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-125-a018de6b4b3f>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (8, 1) for Tensor 'Placeholder_3:0', which has shape '(?, 6)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-a018de6b4b3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mcost_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         print(\"Epoch: \",epoch,\" Training Loss: \",c,\" Training Accuracy: \",\n\u001b[1;32m---> 13\u001b[1;33m               session.run(accuracy, feed_dict={X: train_x, Y: train_y}))\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\avik\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\avik\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    959\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    962\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (8, 1) for Tensor 'Placeholder_3:0', which has shape '(?, 6)'"
     ]
    }
   ],
   "source": [
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for epoch in range(training_epochs):\n",
    "        for b in range(total_batches):    \n",
    "            offset = (b * batch_size) % (train_y.shape[0] - batch_size)\n",
    "            batch_x = train_x[offset:(offset + batch_size), :, :, :]\n",
    "            batch_x = np.reshape(batch_xs, (-1, 9216))\n",
    "\n",
    "            batch_y = train_y[offset:(offset + batch_size), :]\n",
    "            _, c = session.run([optimizer, loss],feed_dict={X: batch_x, Y : batch_y})\n",
    "            cost_history = np.append(cost_history,c)\n",
    "        print(\"Epoch: \",epoch,\" Training Loss: \",c,\" Training Accuracy: \",\n",
    "              session.run(accuracy, feed_dict={X: train_x, Y: train_y}))\n",
    "    \n",
    "    print(\"Testing Accuracy:\", session.run(accuracy, feed_dict={X: test_x, Y: test_y}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
